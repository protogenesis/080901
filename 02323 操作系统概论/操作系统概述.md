# 操作系统概述

## 操作系统概述

### 什么是操作系统

- 操作系统是不同程序代码、数据结构、数据初始化文件的集合，可执行。

- 操作系统提供计算机用户与硬件之间的接口，并管理计算机软件和硬件资源

- 操作系统是用户与硬件之间的接口

	- 硬件接口

		- USB、串口、SATA

	- 软件接口

		- 文件操作fopen、图像显示GUI

	- 计算机所有功能最终都是由硬件的操作来实现

- 操作系统屏蔽了对硬件操作的细节，提供了计算机用户与计算机硬件之间的接口，并且通过这个接口使应用程序的开发变得简单、高效。

- 操作系统必须完成的两个主要目标

	- 为包含在硬件平台上的所有底层可编程部件提供服务

	- 为运行在计算机系统上的应用程序提供执行环境

- 操作系统是资源的管理者

	- 现代计算机系统的一个重要特点是支持多任务，同时驻留多个程序，共同使用计算机软硬件资源

- 主要功能

	- 处理机管理

	- 内存管理

	- 设备管理

	- 文件管理

### 操作系统的发展

- 无操作系统

	- 电子器件

	- 需要人工干预

	- 不能连续自动工作

- 单道批处理系统

	- 电子器件：晶体管
存储：磁性存储设备
操作系统：单道批处理系统

	- 用户程序及程序处理的数据统称为作业

	- 利用存储设备自动装入内存、撤销内存、输出结果，减少CPU等待人工操作作业

	- 内存只能留一道用户作业，CPU和内存被用户作业独占

	- 优点

		- 与无操作系统相比，减少了等待人工操作的时间

	- 缺点

		- CPU利用率低，损失系统的吞吐量

	- 吞吐量：单位时间内计算机系统处理的作业量

	- 特点

		- 自动性

		- 顺序性

		- 单道性

- 多道程序系统（多道批处理系统）

	- 电子器件：集成电路芯片
操作系统：分时操作系统

	- 当运行I/O密集型作业时，CPU等待浪费80%~90%的时间。为了提高CPU利用率，开发了多道程序系统。第一个多道程序系统IBM的OS/360

	- 早期多道程序系统不具有交互功能，被称为多道批处理系统

	- 特点

		- 多道性

		- 无序性

		- 调度性

		- 复杂性

	- 优点

		- 能够提高CPU、内存和I/O设备的利用率和系统的吞吐量

	- 缺点

		- 系统平均周转时间长，缺乏交互能力

- 分时操作系统

	- 为了满足交互功能，产生了分时操作系统，多个用户可以同时通过不同的终端使用主机，主机可以快速响应常用命令

		- 特点

			- 多路性

			- 独立性

			- 及时性

			- 交互性

		- 优点

			- 向用户提供了人机交互的方便性，使多个用户可以通过不同的终端共享主机

		- 缺点

			- 不能及时接收和及时处理用户的命令或数据

	- 第一个通用分时系统CTSS是麻省理工学院于1962年在改装过的IBM7094上开发成功

- 微机操作系统

	- 随着个人计算机的出现，微机操作系统相应产生。第一个微机操作系统是Intel公司的顾问Gary Kildall编写的CP/M系统

	- CP/M于1977年重写，应用于微机CPU，成为著名的8位OS

	- 20世纪80年代初，微软推出了MS-DOS。1985年微软开始构建Windows操作系统

- 实时操作系统

	- 实时系统是支持实时计算的系统。广泛应用于自动控制、智能机器人、海底探测和航空航天等领域

	- 要求在规定时间内完成计算，超时就认为计算错误

	- 实时系统RTOS通常有高可靠性和支持实时资源调度

	- VxWorks操作系统是美国WindRiver公司于1983年设计开发的一种嵌入式实时操作系统

	- uc/OS-II用于微处理器、微控制器和数字信号处理的RTOS内核

	- Linux也支持实时性

	- 特点

		- 多路性

		- 独立性

		- 及时性

		- 交互性

		- 可靠性

	- 实时系统比分时系统要求有更高的可靠性，需要采取多级容错措施来保证系统安全和数据安全

	- 批处理系统、分时系统和实时系统是三种基本的操作系统类型。实际操作系统可能兼有三者或两者的特点

- 嵌入式操作系统

	- 宿主于非计算机设备中的计算机系统

	- 特点

		- 小巧、实时性、可装卸、代码固化、弱交互性、强稳定性、接口统一、低能耗

	- iOS、安卓、Windows 10 IoT Core、FreeRTOS

- 物联网操作系统

### 操作系统的特征

- 并发

	- 并发与并行的区分，并行是多个事件同时发生，并发是多个事件在同一间隔内发生

	- 单CPU多任务，宏观上多个程序都在执行，实际上轮流使用CPU，任意时间只有一个程序在使用CPU

- 共享

	- 指系统中资源供内存中多个并发执行的进程共同使用

	- 互斥共享，任意时刻一个资源只能被一个进程访问，例如打印机

	- 同时共享，资源可以被多个进程同时访问，例如内存访问、磁盘访问

- 虚拟

	- 时分复用，打印机

	- 空分复用，网络带宽

- 异步性

### 操作系统的功能

- 内存管理

	- 内存分配

		- 主要任务是为每道程序分配内存空间

		- 两种方式实现：静态分配方式和动态分配方式

		- 为了实现内存的分配，需要以下数据结构和功能支持

			- 用于内存分配数据结构

			- 内存分配功能

			- 内存回收功能

	- 内存保护

		- 使操作系统内核的空间不会被用户随意访问，以保证系统的安全和稳定

		- 确保每道用户程序都在自己的内存空间中运行，互不干扰

	- 内存扩充

		- 借助于虚拟存储技术，从逻辑上扩充内存容量，使系统能够向用户提供比物理内存大的存储容量

		- 为了能从逻辑上扩充内存，系统必须具有内存扩充机制，以实现请求调入和置换功能

	- 地址映射

		- 把程序的逻辑地址转变为物理地址，这个转换的过程称为地址映射

- 进程管理（处理机）

	- 进程的描述与组织

	- 控制

	- 同步

	- 通信

	- 调度

- 设备管理

	- 主要完成用户的I/O请求，为用户分配I/O设备

	- 具有以下功能

		- 缓冲管理

		- 设备分配

		- 设备处理

		- 设备独立性和虚拟设备

- 文件管理

	- 目录管理

	- 文件的读、写管理和存取控制

- 提供用户接口

	- 命令接口

		- 联机

		- 脱机

	- 图形用户接口

	- 程序接口

### 操作系统的体系结构

- 为软件系统提供了一个结构、行为和属性的高级抽象，包括

	- 系统元素的结构

	- 元素间的相互关系

	- 指导元素集成的模式和约束

- 体系结构模型

	- 简单的监控程序模型

		- 无操作系统概念，所有功能集中在一个模块

	- 单体结构模型

		- 所有软件和数据结构放在一个逻辑模块中，对外提供系统调用接口

		- 单体内核是操作系统最早、最常见的体系结构

		- MS-DOS、Linux、Mac OS X、BSD

	- 层次结构模型

		- 将操作系统分解为多个小的、容易理解的层

		- 系统功能被隔离在不同层中，每一层提供对系统功能的部分抽象

		- 层间采用单向调用的顺序，形成一连串彼此连续的对系统功能的抽象，最终形成对整个系统的完整抽象

		- THE系统

	- 客户/服务器模型与微内核结构

		- 微内核技术是操作系统发展的里程碑

		- 微内核结构用一个水平分层的结构代替了传统的纵向分层的结构

		- 将系统内核功能以服务形式提供接口调用

		- 缺点是效率不高

		- 两个发展方向：通用操作系统，嵌入式操作系统

		- Windos NT、COSIXV2.3、Mach、Vxworks 

	- 动态可扩展结构模型

		- 在运行过程中，能够动态地实现系统行为扩展的结构，也可称之为弹性结构

		- UPCALL和DOWNLOAD

### 指令的执行

- 程序是指令的集合，程序的执行就是按照某种控制流执行指令的过程

- 一个单一指令需要的处理称为指令周期

	- 取指周期和执行周期

- 在每个指令周期开始时，处理器从存储器中取一条指令

- 取到的指令被放置在处理器的指令寄存器IR中

- 处理器解释指令并执行要求的动作，这些动作分为4类

	- 处理器与存储器之间的指令或数据传送操作

	- 处理器与I/O设备之间的指令或数据传送操作

	- 逻辑运算操作

	- 控制操作

- 内部 CPU 寄存器

	- 程序计数器

		- 下一条要执行的指令的地址

	- 指令寄存器

		- 存正在执行的指令

	- 累加器

		- 临时存储体

## 进程管理

### 进程的描述

- 定义

	- 进程是允许并发执行的程序在某个数据集合上的运行过程

	- 进程是由正文段、用户数据段及进程控制块共同组成的执行环境

		- 正文段

			- 描述进程要完成的功能，存放机器指令

		- 数据段

			- 进程执行时直接进行操作的用户数据

		- 进程控制块 PCB

			- 存放程序的运行环境

- 特征

	- 并发性

		- 多个进程同时运行，现代操作系统的重要特征

	- 动态性

		- 进程实体的执行过程，创建--执行--消亡

	- 独立性

		- 资源独立，互不干扰

	- 异步性

		- 速度不可预知，执行随机

	- 结构特征

		- 进程由正文段、用户数据段、进程控制块组成

- 程序请求的顺序执行

	- 顺序性：下一操作要等待前一操作结束

	- 封闭性：执行独占资源，不受外界影响

	- 可再现性：重复执行将获得相同结果

- 程序的并发执行

	- 程序并发执行是指同一时间间隔内运行多个程序。一个程序执行结束之前，可以运行其他程序。

	- 特征

		- 间断性

		- 失去封闭性

		- 不可再现性

- 进程与程序

	- 比较

		- 进程是动态，程序是静态的

		- 进程是暂时，程序是永久

		- 存在实体不同，程序是指令集合，进程由正文段+数据段+PCB组成

	- 联系

		- 进程是程序的一次执行

		- 一个程序可以对应多个进程

			- 一个程序对应不同数据集合运行多个进程

			- 多个进程并发执行同一个程序代码

- 操作系统管理进程使用的数据结构

	- 进程控制块PCB

		- 描述

			- 每个进程有唯一PCB

			- PCB是进程存在的唯一标志

			- OS通过PCB控制和管理进程

			- OS通过PCB感知进程的存在

		- 包含信息

			- 进程标识符PID：唯一标识一个进程

			- 处理机状态信息：处理机内各种寄存器的内容

				- 通用寄存器，用户程序访问的寄存器

				- 指令计数器

				- 程序状态字

				- 用户栈指针，用户进程相关的系统栈

			- 进程调度信息：进程状态、优先级、调度等信息

			- 进程控制信息：进程资源信息

				- 程序和数据地址、进程同步和通信机制、资源清单、链接指针

		- 操作系统把具有相同状态的进程的进程控制块（PCB）组成一个进程队列，通常有索引和链接两种组织方式

- 三种状态

	- 就绪态：已获得CPU以外所有资源，处于就绪队列

	- 执行态：获得CPU，处于执行过程

	- 阻塞态：发生某种事件暂时无法进行，放弃CPU处于暂停状态，如请求I/O，请求缓冲空间，处于阻塞队列

	- 状态的转换

		- 就绪态  -> 执行态，调度操作

		- 执行态 -> 就绪态，时间片机制

		- 执行态 -> 阻塞态，阻塞操作

		- 阻塞态 -> 就绪态，唤醒操作

### 进程的控制

- 创建的起因

	- 用户登录

	- 作业调度

	- 提供服务

	- 应用请求

- 创建的步骤

	- 申请空白 PCB

	- 为新进程分配资源

	- 初始化进程控制块

	- 将新进程插入就绪队列

- 创建的关系

	- 父进程：由系统或用户首先创建的进程

	- 子进程：父进程创建的进程

	- 父子进程关系

		- 进程控制：子进程由父进程创建或撤销，子进程不能控制父进程

		- 资源继承：子进程可以全部或部分共享父进程的资源

		- 运行方式：可同时进行，可以控制先后

		- 数据结构：在PCB中设置家族关系表项，标明自己的父进程和子进程

- 进程阻塞

	- 起因

		- 请求系统服务

		- 启动某种操作

		- 新数据尚未到达

		- 无新工作可做

	- 过程

		- 将进程的状态改为阻塞态

		- 将进程插入相应的阻塞队列

		- 转进程调度程序，从就绪进程中选择进程为其分配 CPU

- 进程唤醒

	- 过程

		- 将进程从阻塞队列中移除

		- 将进程状态由阻塞态改为就绪态

		- 将进程插入就绪队列

- 进程中止

	- 起因

		- 正常结束

			- halt, Logoff

		- 异常结束

			- 越界错误，保护错，非法指令，特权指令错，运行超时，等待超时，算数运算错，I/O 故障

		- 系统调用

			- 操作员或 OS 干预，父进程请求/终止

	- 过程

		- 从进程 PCB 中读进程状态

		- 若进程正在执行，则终止进程的执行

		- 若进程有子孙进程，在大多数情况下需要终止子孙进程

		- 释放资源

		- 将终止进程的 PCB 移出

- 操作系统的启动和进程变化

	- 硬盘启动

		- 如果是单系统，引导扇区是0柱面0磁道1扇区，BIOS将它装入到内存，并开始加载操作系统

		- 如果是多分区多系统，主引导扇区是0柱面0磁道1扇区，会通过它判断当前激活分区，再加载相应的操作系统

	- OS 启动过程

### 操作系统内核

- 是计算机硬件的首次扩充，内核执行OS与硬件相关的功能

- 功能

	- 支撑功能

		- 中断处理

			- 改变CPU执行指令顺序的一种事件

			- 中断类型

				- 同步中断（内部中断）

					- 执行异常（出错、调试、溢出）

				- 异步中断（外部中断）

					- 由其他硬件设备引发

					- 可屏蔽/不可屏蔽

			- 中断原因

				- 人为设置

				- 程序性事件

				- 硬件故障

				- I/O 设备

				- 外部事件

			- 中断响应

				- 响应时机

					- 每执行完一条指令后，检测一次是否有中断信号

			- 中断过程

				- 中断检测

				- 响应中断（关中断）

				- 保护现场

				- 执行中断服务子程序（处理中断原因的事件）

					- CPU 层次，使用中断向量

					- 操作系统层次，使用中断描述符表

				- 恢复现场

				- 开中断

				- 继续执行

		- 时钟管理

			- 操作系统内核利用时钟机制防止单个进程垄断CPU

			- 系统时钟

				- 实时时钟，RTC时钟，CMOS时钟

				- OS时钟，产生于主板定时/计数芯片

		- 原语操作，原语操作是一种原子操作，不可分割，不能中断，例如阻塞原语block，唤醒原语wakeup

	- 资源管理功能

		- 进程管理

		- 存储器管理

		- 设备管理

- 操作系统内核需要完成两种定时测量

	- 保存当前日期时间

	- 维持定时器

- 操作系统依靠两种方法完成定时测量

	- OS时钟管理硬件（可编程间隔定时器PIT）

	- 时钟软件，时钟驱动程序

- 系统调用

	- 一群预定义模块

	- 它们提供一条管道为应用程序或用户提供核心程序服务

	- 系统调用是系统程序和用户程序之间的接口

	- 系统调用和一般函数调用的区别

		- 系统调用运行在系统态（核心态），而一般函数运行在用户态

		- 系统调用与一般函数调用的执行过程不同。系统调用执行时，当前进程被中断，由系统找响应的系统调用子程序，并在系统态下执行，执行结果返回进程

		- 系统调用要进行中断处理，比一般函数调用多了一些系统开销

	- 系统调用类型

		- 进程控制类

			- 创建、撤销进程；获得、改变进程属性

		- 文件操纵类

			- 创建、删除、打开、关闭、读写文件

		- 设备管理类

			- 请求、释放设备

		- 通信类

			- 打开、关闭连接，交换信息

- 用户态执行

	- 用户空间是指用户进程所处的地址空间，一个用户进程不能访问其他进程的用户空间，只有系统程序才能访问其他用户空间。当 CPU 执行用户空间的代码时，称该进程在用户态执行

- 系统态执行

	- 系统空间是指一切系统核心代码的地址空间，当 CPU 执行系统核心代码时，称进程处于系统态执行

### 进程同步

- 概念

	- 进程之间存在资源共享关系和相互合作关系

- 任务

	- 具有资源共享关系的进程以互斥方式访问临界资源。
临界资源是指必须以互斥方式访问的共享资源

	- 具有相互合作关系的进程保证进程协调执行，可能同时存在资源共享的关系

- 共享资源以互斥方式访问的原因

	- 为了保证正确性，操作系统把共享资源作为临界资源管理，被进程互斥访问

- 同步机制的准则

	- 空闲让进

	- 忙则等待

	- 有限等待

	- 让权等待：释放CPU、避免忙等

- 实现

	- 信号量机制

		- 整型信号量机制

			- 使用一个代表资源数目的整型变量，即一个信号量且是整数变量

			- 两个标准原子操作访问信号量：wait(S)和signal(S)，简称P、V操作

			- 总结

				- 整型信号量的值只能由 wait 和 signal 操作改变

				- wait 和 signal 操作都是原子操作，即在这两个操作中对信号量的访问是不能被中断的

				- 原子操作可以通过关中断来实现

				- 整型信号量机制的实例：Linux 中的自旋锁 SpinLock

				- 不同的资源对应不同的信号量，并不是系统中所有的资源都用同一个信号量表示

			- 最大缺点存在忙等，不满足让权等待

		- 记录型信号量机制

			- 不存在“忙等”现象，采取“让权等待”的策略

			- 增加一个进程链表L ，用于链接所有等待进程

				- 等待进程使用阻塞操作进入进程链表L

			- 信号量S是一个结构体

			- 记录型信号量机制的初值S.value含义

				- 初值为1，表示只允许一个进程访问临界资源，信号量转化为互斥信号量

				- >0，有可用资源数量，不必阻塞

				- <0，阻塞进程个数

				- =0，临界状态，无可用资源

					- 如果是+1后变0，则表示唤醒最后一个阻塞进程

					- 如果是当前状态为0，则下一个wait操作会引发阻塞

		- AND型信号量机制

			- 思想

				- 只要有一种资源不满足就全部不分配，全部满足就全部分配

	- 生产者-消费者问题的总结

		- 互斥（公用）信号量，在单个程序中必须成对地出现

			- 例如实现互斥的wait(mutex)和signal(mutex)

		- 资源（私用）信号量empty和full的wait和signal操作，同样需要成对地出现，但它们分别处于不同的程序中

			- 例如，wait(empty)在计算进程中，而signal(empty)则在打印进程中，计算进程若因执行wait(empty)而阻塞， 则以后将由打印进程将它唤醒

		- 每个程序中的多个wait操作顺序不能颠倒，“先私后公”，先执行资源信号量wait操作，再执行互斥信号量wait操作，否则可能引起进程死锁

		- 每个程序中的多个signal操作顺序可以颠倒

	- 信号量机制的不足

		- 临界区分布在不同进程中，不便于管理与控制

		- 很多临界区操作是相同的，代码重复编写，耗费工作量

		- 程序中加入wait和signal操作，结构不清晰，可读性差

		- 程序中若出现错误，常因为阻塞而不便于调试跟踪

		- 程序中若wait和signal编写错误，难于预测而且易引发死锁

	- 管程

		- 管程是描述共享资源的数据结构+数据结构上共享资源管理程序的集合

		- 管程包括：变量的定义、变量的初始化、管理共享资源的过程

		- 管程是供程序员调用的软件包，每次只有一个进程调用管程，即任意时刻管程上只有一个活跃进程，若多个进程调用同一个管程，只有一个进程能进入管程

		- 管程是一种编程语言的构件

		- 管程的条件变量

			- 管程中对每个条件变量，都须予以说明

			- 条件变量即带PV操作的变量，定义为Var x, y:condition

			- 原有的wait和singal操作改成与变量绑定，X.wait和X.signal

			- 对变量X的操作放在X.wait和X.signal之间

### 进程通信

- 信号量机制属于进程间的低级通信

- 高级进程通信类型

	- 共享存储器，Share Memory，信息无格式

		- 共享数据结构、共享存储区

	- 消息传递，Message Passing，信息格式化

		- 直接通信、间接通信

	- 管道通信，以文件方式连接读写进程

	- 消息缓冲队列

		- 广泛应用本地进程通信

		- 包括数据结构、发送原语、接收原语

### 线程

- 进程的不足

	- 为使程序能并发执行，系统必须进行系列操作：创建、撤消、切换进程

	- 进程同时作为资源分配单位与调度分派单位，限制了并发程度的进一步提高

	- 进程“太重”，需要分割进程功能，引入线程

- 与进程的关系

	- 资源与调度：线程是程序执行的基本单位，进程是拥有资源的基本单位

	- 地址空间资源
不同进程的地址空间独立
同一进程的线程共享进程的地址空间

	- 通信关系
进程之间用进程通信机制
同一进程的线程直接读写或共享全局变量

	- 并发性：
多进程之间、多线程之间、同一进程多线程之间，都可并发

	- 系统开销：线程开销更小

- 概念

	- 线程是进程的一个实体，是独立调度和分派的基本单位

	- 线程作为利用CPU的基本单位，是花费开销最小的实体

	- 线程只包含运行所需的资源，即CPU资源，但它可以共享进程资源

- 分类

	- 用户级线程

	- 内核级线程

- 状态

	- 就绪

	- 运行

	- 阻塞

- 线程控制块 TCB

	- TCB 的定义

	- TCB 包含的信息

	- 线程组织方式：采用链接队列

- 线程控制

	- 创建与终止

	- 调度与切换，调度可以为一个进程的多个内核线程分配多个CPU

	- 阻塞与唤醒

- 线程的同步

	- 类似进程，有原语操作、信号量机制

- 线程通信

	- 同一进程的线程之间，直接用全局变量通信

	- 不同进程的线程之间，使用操作系统提供的线程通信机制

## 进程调度与死锁

### 进程调度的功能与时机

- 操作系统的三级调度

	- 磁盘（作业调度，高级调度）

	- 内存（进程置换，中级调度）

	- CPU（CPU 调度，低级调度）

- 功能

	- 按某种策略或算法，从就绪态进程中选择一个新进程运行在CPU上

		- 由操作系统内核的进程调度程序完成

- 时机

	- 进程结束

	- 进程阻塞

	- 中断返回

	- 抢占式调度

	- 时间片用完

- 准则

	- 周转时间短

	- 响应时间快

	- 截止时间的保证

	- 系统吞吐量高

	- 处理机利用率好 

### 进程调度算法

- 术语

	- 开始时间：首次使用CPU的时间

	- 服务时间：需要使用CPU的时间，又叫运行时间

	- 完成时间：退出系统的时间，又称结束时间

	- 周转时间 = 完成时间-到达时间，包含服务时间和等待时间，若等待时间为0即没有等待

	- 带权周转时间： 周转时间 / 服务时间

- 先来先服务调度算法FCFS

	- 从就绪队列中，选择最先进入队列的进程，即队首进程

	- 优点：实现简单，算法开销小，有利于长时间作业（进程）

	- 缺点：不利于短时间作业（进程）

	- 下一个进程的开始时间=上一个进程的完成时间

	- 完成时间=开始时间+服务时间

	- 等待时间=开始时间-进入时间

	- 周转时间=完成时间-进入时间

	- 带权周转=周转时间/服务时间

- 短进程优先调度算法

	- 优先选择运行时间最短的进程

	- 非抢占式调度

	- 优点：有利于短作业或短进程

	- 缺点：导致长作业或进程长时间不被调度，不能保证实时性，执行时间一般基于用户估算，准确性不足

	- 与FCFS的对比

		- 短进程优先能有效降低进程的平均等待时间，提高系统的吞吐量

- 优先权调度算法

	- 每个进程有一个关联的优先权，将优先权最高的进程分配给CPU

	- 非抢占式优先权算法

	- 抢占式优先权调度算法

		- 抢占式不考

	- 优先权类型

		- 静态优先权：创建进程时已确定并在运行过程中不变

			- 因素：进程类型、进程对资源的需求、用户要求

		- 动态优先权：随进程的推进或等待时间增加而改变

			- 因素：等待时间越长则提高优先权

	- 主要问题是无穷阻塞问题（饥饿问题）

		- 解决方法是老化技术，逐渐增加等待时间很长的进程的优先权

- 时间片轮转调度算法

	- 步骤

		- 将所有就绪进程按先来先服务排成队列

		- 把CPU分配给队首进程，进程只执行一个时间片

		- 时间片用完，OS通过计时器发出时钟中断，停止进程

		- 将已使用时间片的进程送往就绪队列的末尾

		- 分配处理机给就绪队列的下一进程

	- 时间片大小的设定影响系统性能

		- 大小的要求：满足用户交互，同时使大多数进程在一个时间片内完成

	- 时间片大小的确定因素

		- 系统对响应时间的要求

		- 就绪队列中进程的数目

		- 系统的处理能力

	- 时间片轮转调度算法的性能

		- 算法性能依赖于时间片大小

		- 时间片太大，算法变成FCFS

		- 时间片太小，进程需要多次调度和切换，浪费CPU用于调度和切换的新开销

- 多级队列调度

	- 概念

		- 就绪队列不止一个，根据进程的不同要求，采用多级队列调度

	- 步骤

		- 将就绪队列分成多个独立队列

		- 按照进程的属性，如占用内存大小、进程优先权、进程类型等，将进程永久分配到一个队列

		- 每个队列有自己的调度算法

		- 不同队列的优先权不同

		- 示例Minix操作系统的进程调度

- 多级反馈队列调度

	- 解决多级队列把进程永久分配到某个队列的不足

	- 设置多个就绪队列

	- 各个队列优先级逐个降低，各个队列时间片逐个增加

	- 优先级越高的队列执行时间片就越短，一般时间片按倍增规则

	- 整合了时间片、 FCFS、优先级三种机制

	- 典型实例：Linux2.6.11内核的进程调度算法

	- 是时间片长度不唯一，分级设置的多级队列调度算法

### 实时系统调度

- 实时系统对处理器操作或数据流动有严格的时间限制

	-  

	-  

- 实时系统的进程调度对保证时间要求有重要作用

	- 开始截止时间：必须在指定时间之前开始

	- 完成截止时间：必须在指定时间之前完成

	- 实时任务：必须在截止时间之前开始或结束

- 基本条件

	- 提供必要信息

		- 就绪时间

		- 开始截止时间和完成截止时间

		- 处理时间、资源要求、优先级

	- 系统处理能力强

	- 采用抢占式调度机制

		- 基于时钟中断的抢占式调度（毫秒）

		- 立即抢占的优先权调度（微秒）

	- 具有快速切换机制

		- 对外部中断的快速响应能力

		- 快速的任务分派能力

- 最早截止时间优先(EDF, Earliest Deadline First)算法

	- 根据任务的开始截止时间确定任务优先级

	- 开始截止时间越早，优先级越高

- 最低松弛度优先(LLF, Least Laxity First)算法

	- 根据任务紧急(或松弛)的程度确定任务的优先级

	- 任务的紧急程度愈高，优先级就愈高

	- 临界状态发生抢占

	- 松弛度 = 完成截止时间 – 处理时间 – 当前时间

### 进程切换

- 概念

	- 用新选择的进程替换原来执行的进程，将CPU控制权交给新进程

- 步骤

	- 保存包括程序计数器和其他寄存器在内的 CPU 上下文环境

	- 更新被替换进程的进程控制块

	- 修改进程状态，把执行态改为就绪态或者阻塞态

	- 将被替换过程的进程控制块移动到就绪队列或阻塞队列

	- 执行通过进程调度程序选择的新进程，并更新该进程的进程控制块

	- 更新内存管理的数据结构

	- 恢复被调度程序选中的进程的硬件上下文

### 多处理器调度

- 多处理器系统类型

	- 紧密耦合，共享内存和其他I/O设备

	- 松弛耦合，通过通道或通信线路实现多台计算机互连

	- 对称，同构的处理器系统

	- 非对称，多种类型的处理器系统，一个主处理器和多个从处理器

- 对称多处理器系统的进程分配

	- 静态分配，每个处理器有独立的就绪队列

	- 动态分配，所有处理器有公共的就绪队列

- 非对称多处理器系统的进程分配

	- 主-从式操作系统，主处理器执行调度程序，分配从处理器

- 多处理器的进程(线程)调度

	- 自调度，最常用的方式，一个公共的就绪队列，哪个CPU空闲就分配

	- 成组调度，将一组相互合作的进程或线程分配给一组CPU，减少线程切换和调度开销

	- 专用处理器分配，专门为一个应用程序分配一组处理器

		- 适用高并发的处理器环境

		- 适用具有成百上千个处理器的并行系统

		- 由于程序专用，避免了进程切换，加快程序完成

### 死锁

- 概念

	- 多个进程因竞争资源而造成的一种僵局，若无外力作用，这些进程都将永远不能再向前进

- 造成原因

	- 竞争共享资源

	- 分配资源的顺序不当

- 产生条件

	- 互斥条件：资源不能被多个进程同时使用

	- 请求和保持条件：进程至少持有一个资源，同时请求其他资源

	- 不剥夺条件：已分配给进程的资源在未使用完之前，不能被强制剥夺

	- 环路等待条件：存在一个进程循环等待资源的链条，形成一个闭环

- 处理方法

	- 预防死锁

		- 基本思想是破坏产生死锁的一个或多个必要条件

		- 由于并发必定会产生互斥操作，所以不能摒弃互斥条件

		- 只能破坏另外三个条件

			- 摒弃“请求和保持”条件

				- 资源一次性分配

				- 优点：简单，易于实现，安全

				- 缺点：资源浪费严重，进程延迟执行

			- 摒弃“不剥夺”条件

				- 当资源请求不能满足，强行回收已分配资源

				- 缺点：被剥夺资源的进程的工作全部作废，代价高

				- 缺点：被剥夺资源的进程又申请资源，资源反复申请，性能下降

			- 摒弃“环路等待”条件

				- 对资源排序，资源申请必须按照规定的顺序进行

				- 缺点：限制了新资源的增加

				- 缺点：系统设置资源分配顺序和应用实际使用顺序不一致，造成资源浪费

				- 缺点：对用户编程带来麻烦

	- 避免死锁

		- 把系统资源分配状态分为安全状态和不安全状态。
如果资源分配后，系统处于安全状态，就不会发生死锁

		- 方法

			- 在每次资源分配前，计算资源分配安全性

			- 如果分配不会导致系统进入不安全状态，就同意分配

			- 如果分配导致系统进入不安全状态，就拒绝分配

		- 系统安全状态

			- 安全状态是指系统能按某种进程顺序来分配资源，使每个进程都可顺利地完成，称这个顺序的进程序列为安全序列

			- 如果系统无法找到这样一个安全序列，则称系统处于不安全状态

		- 银行家算法

			- 假设当前状态安全，当有新的资源分配请求，执行算法判断新的请求是否安全，决定是否同意请求

			- 属于避免死锁

			- 过程

				- 假设当前状态安全，有新的资源分配请求

				- 虚拟执行新的分配请求，使得当前状态进入下一个状态

				- 在下一个状态中寻找安全序列

				- 若找到，就说明状态是安全，同意执行分配请求

				- 否则拒绝分配请求

			- 银行家算法由Dijkstra提出，由很多理论研究，但缺乏实用价值

				-  很少进程能够在运行前知道它所需资源的最大值

				- 系统内的进程数是不固定的，往往在不断变化，有新的进入，有完成的退出

				- 可用资源可能突然发生故障变为不可用，例如磁带机、硬盘读写故障

				- 算法开销大，实时性不好

	- 检测并解除死锁

		- 不采取事先预防和避免的方法来解决死锁问题

		- 检测死锁是否发生，如果检测到有死锁，再解除死锁

		- 采用资源分配图检测死锁

			- 结点表示进程

			- 方框表示资源

			- 资源数量等于方框内圆圈数量

			- 进程占有资源：资源指向结点的有向边

			- 进程请求资源：结点指向资源的有向边

			- 占有或请求数量等于边的数量

		- 死锁定理

			- 如果资源分配不可完全简化，则处于死锁状态

		- 解除死锁的两个途径

			- 终止处于死锁的进程

				- 终止进程的两种方式

					- 终止所有死锁进程

					- 逐个终止，回收资源，直到死锁解除

			- 抢占死锁进程占有的资源

				- 抢占资源需要考虑的3个问题

					- 抢占哪个进程的哪些资源

					- 抢占资源后要通过回滚保证进程正常

					- 抢占资源要避免进程处于饥饿状态

	- 忽略死锁（假定死锁不可能发生）

## 内存管理

### 存储器层次结构

- 多级存储器结构

	- 通用存储层次：CPU寄存器、主存、辅存

	- 具体功能

		- 寄存器

		- 高速寄存器（Cache）

		- 主存储器

		- 磁盘缓存

		- 固定磁盘

		- 可移动存储介质

	- 局部性原理

		- 1968年， Denning.P提出

		- 程序执行时， 除了少部分的转移和过程调用指令外， 在大多数情况下仍是顺序执行的

		- 过程调用将会使程序的执行轨迹由一部分区域转至另一部分区域， 但经研究看出，过程调用的深度在大多数情况下都不超过5

		- 程序中存在许多循环结构， 这些虽然只由少数指令构成， 但是它们将多次执行

		- 程序中还包括许多对数据结构的处理， 如对数组进行操作， 它们往往都局限于很小的范围内

	- 局限性

		- 时间局限性

			- 如果程序中的某条指令一旦执行， 则不久以后该指令可能再次执行；如果某数据被访问过， 则不久以后该数据可能再次被访问

				- 大量的循环操作

		- 空间局限性

			- 一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内

				- 程序的顺序执行

### 程序的链接和装入

- 程序进入内存的流程步骤

	- 编译：源代码→目标模块

	- 链接：目标模块+库函数→装入模块

	- 装入：装入内存

- 程序的静态链接方式(Static Linking)

	- 程序运行之前，先将各目标模块及它们所需的库函数，链接成一个完整的装配模块，以后不再拆开

	- 静态链接在装入内存

- 程序的动态链接(Run-time Dynamic Linking)

	- 程序执行中需要该(目标)模块时，才对它进行的链接

	- 执行过程中，当发现一个被调用模块尚未装入内存时，立即由OS去找到该模块并将之装入内存， 把它链接到调用者模块

	- 不用的目标模块不会被调入内存和被链接到装入模块

	- 加快程序的装入过程，而且可节省大量的内存空间

- 程序的装入

	- 绝对装入：绝对映射，程序中逻辑地址与内存物理地址完全相同

		- 程序的逻辑地址与实际内存地址相同

	- 可重定位装入：静态映射，在装入时对逻辑地址进行修改

		- 在装入时对逻辑地址做一次性修改，以后不再改变

	- 动态运行时装入：逻辑地址到物理地址的映射在程序运行时才执行

		- 地址转换到程序真正要执行时才进行

		- 装入内存后的所有地址都仍是相对地址

### 连续分配存储管理方式

- 概念

	- 为每个用户程序分配连续的内存空间

- 单一连续分配

	- 一个用户程序独占连续的内存用户空间

	- 用于单用户，单任务的OS中

	- 内存只分为两个区：系统区和用户区

	- 一般对系统区作保护，用基址寄存器做控制

- 固定分区连续分配

	- 将内存划分多个区域，每个区域大小固定

	- 每个区域只能装入一个程序

	- 分区大小相等的划分方法，一般用于多个相同任务

	- 分区大小不等的划分方法，根据实际任务大小分配

	- 固定分区分配容易造成浪费

- 动态分区分配

	- 无固定分区，在整块内存空间中动态分割

	- 无用户程序，内存是一整块连续分区

	- 根据程序大小动态地分配连续的内存空间，分配的内存大小等于程序大小

	- 关键元素

		- 分区数据结构

			- 空闲分区表

			- 空闲分区链

		- 分配算法

		- 分配和回收操作

	- 算法

		- 首次适应：按顺序选择第一个满足要求的内存区域

		- 循环首次适应：在上一次找到空闲分区的下一个分区开始寻找，找到第一个满足要求的内存区

		- 最佳适应：在所有空闲分区中查找与程序大小最相近的空闲分区

	- 动态分区分配流程

		-  

- 动态重定位分区分配

### 基本分页存储管理方式

- 引入：非连续分配，离散地分布在内存不同位置

- 基本概念

	- 页：逻辑上的划分，进程空间管理上的划分

	- 页是操作系统分配内存的最小单位

	- 页框：物理上的划分，内存中的划分，又称为存储块、页帧

	- 分页存储：在为进程分配内存时，以页框为单位，把进程中的若干页装入内存多个不一定相邻的页框中

	- 页内碎片：进程的最后一页装不满一页框，形成了不可利用的碎片

	- 页表：记录进程页和内存页框的对应关系

		- 页表第1列是页号，是连续的

		- 页表第2列是页框号，是离散的

- 分页地址变换过程

	- PCB将页表地址和长度送到CPU

	- CPU访问逻辑地址L

	- 分页地址变换机构自动将逻辑地址分为页号和页内地址

	- 由硬件检索页表，得到对应的页框号

	- 页框号和页内偏移地址求得物理地址

- 页大小设计的影响因素

	- 管理内存的开销

	- 内存的利用率

	- 页大小： 一般是2的n次幂，通常为512B~4KB

- 地址变换的缺点

	- 需要访问两次内存才能取出数据

	- 一次访问页表，查找页框号，计算物理地址

	- 一次根据物理地址读取数据

- 具有快表(TLB)的地址变换机构

	- 快表是高速存储器，具有并行查找功能

	- 快表访问速度一般是内存的几倍

	- 将页表部分内容存在快表，一般存放当前使用的页表项

	- 快表主要用于减少逻辑地址到物理地址的转换时间

- 带快表的地址变换过程

	- CPU自动分页，并将页号送入TLB

	- 若TLB找到页框号，则求得物理地址

	- 若页号不在TLB，从页表查找页框号，再求得物理地址，并把该页号和页框号写入TLB

- 单级页表的缺陷

	- 页表一般是数组的形式，空间分配属于连续分配

	- 页表大小不能超过单个页框大小

	- 当逻辑地址空间很大时，导致页表占用内存空间很大

	- 例如地址长度32位，可以得到最大空间为4GB，页表大小4KB，最多包含4G/4K=1M个页；若每个页表项占用4个字节，则页表最大长度为4MB，即要求内存划分出连续4MB的空间来装载页表，而且页表采用的是连续分配，不是分页分配

	- 因此引入两级或多级页表

- 两级页表

	- 对页表本身采用分页式管理，对页表本身增加了一层页表管理

	- 地址结构：页目录号+页号+页内偏移地址

	- 两级页表的逻辑地址结构与地址变换

- 多级页表

	- 32位系统采用两级页表结构是合适的

	- 对于64位系统，一般用三级页表

	- 设页表大小4KB，则页内地址为12位，页号为12位，则页目录号有42位，即最多可以有4096G个页表项，实际并不需要这么多
64位系统最大支持空间264=1844744 TB ，目前实际只使用48位，采用三级页表就可以了

### 基本分页的虚拟存储系统

- 常规存储器管理面临的问题

	- 单个作业很大，要求的内存超过总容量

	- 大量作业要求进入，要求总量超过总容量，使得并发数量受限制

- 常规存储器管理方式的特征

	- 一次性：内存浪费，每个作业都是一次性全部装入内存

	- 驻留性：占用资源，不使用部分长期占用内存

- 虚拟存储

	- 基本思想

		- 先将进程的一部分装入内存，其他部分什么时候需要，再请求OS装入，即请求调入功能

		- 置换

	- 特征

		- 离散性

		- 多次性

		- 对换性

		- 虚拟性

	- 好处

		- 提高内存利用率

		- 提高多道程序利用度

		- 把逻辑地址空间和物理地址空间分开，使程序员不用担心物理内存的容量对编程的限制

- 虚拟存储器

	- 是指具有请求调入功能和置换功能， 能从逻辑上对内存容量加以扩充的一种存储器系统

	- 特征

		- 其逻辑容量由内存容量和外存容量之和所决定

		- 其运行速度接近于内存速度

		- 成本接近于外存

	- 请求分页的虚拟存储系统

		- 在基本分页系统上增加请求调页功能和页面置换功能

		- 发生缺页就请求调页

		- 内存不足，就换出暂时不运行的页面

	- 硬件支持

		- 页表机制

			- 纯分页的页表机制上增加若干项

			- 状态位：指示本页是否已经调入内存

			- 访问字段：记录本页在一段时间内访问的次数

			- 修改位：本页在调入内存后是否被修改过

			- 外存地址：本页在外存中的物理位置，一般是页框号

		- 缺页异常机构

			- 当要访问的页面不在内存便产生缺页中断，以请求OS将所缺的页调入内存

			- 保存CPU现场

			- 分析中断原因

				- 一条指令执行期间可能发生多次缺页中断，最多可达6次

				- 指令本身跨两个页面，源地址和目标地址也可能跨两个页面

			- 缺页中断处理

			- 恢复CPU现场

		- 地址变换机构

			- 地址变换过程

				-  

		- 内存分配策略和分配算法

			- 进程不是一次性完全装入内存，内存页框数量有限，需要确定每个进程的页框分配

			- 最小页框数的确定

				- 是指能保证进程正常运行所需的页框最少数量

				- 取决于指令的格式、 功能和寻址方式

				- 单地址指令+直接寻址，最少页框数为2。一块存放指令，一块存放数据

				- 系统支持间接寻址时，则至少要求有3个页框

				- 若多字节指令，指令本身跨两个页面，源地址和目标地址也可能跨两个页面，共涉及6个页面框的分配算法

			- 页框的分配策略

				- 固定分配局部置换：每个进程的页框数量固定，每次页面置换都在进程自身的页框中进行

				- 可变分配全局置换：OS保留一定的空闲页框，根据进程需要动态分配。若无空闲页框，页面置换选择任一进程的页框，由算法决定

				- 可变分配局部置换：分配同上，页面置换在进程自身的页框中进行

				- 分配策略的评价指标：并发进程数、缺页率

			- 页框的分配算法

				- 页框平均分配

					- 所有空闲页框平均分配给各个进程

				- 页框按比例分配

					- 根据进程大小按比例分配页框

				- 页框按优先权分配

					- 对重要的、紧迫的作业分配较多的空间

- 调页策略：何时、何处调入页面

	- 何时调入页面

		- 预调入页策略：发生缺页时，一次性调入多个相邻页

		- 请求调页策略：发生缺页时，只调入缺页

	- 何处调入页面

		- 外存分为文件区和对换区，分三种策略

			- 对换区采用连续分配，文件区采用离散分配，对换区访问O速度比文件区高

				- 全部从对换区调入，要求进程运行前将所有文件从文件区拷贝到对换区

				- 先从文件区调入；若页面被修改则换出时放入对换区，以后从对换区调入；未修改页面下次仍从文件区调入

				- 未运行页面从文件区调入；运行过且被换出的页面从对换区调入

	- 页面调入过程

		- 若访问页面未在内存，向CPU发出一缺页中断

		- 中断处理程序首先保留CPU环境，分析中断原因，转入缺页中断处理程序

		- 缺页中断处理程序查找页表，得到该页在外存的页框号

		- 若内存能容纳新页，则启动磁盘I/O将缺页调入内存

		- 若内存已满，按照某种置换算法选出一页准备换出；如果该页未修改，该页不必写回磁盘；若该页已被修改， 则必须写回磁盘，调到步骤4

		- 修改页表，置存在位为1，并将此页表项写入快表中

		- 利用修改后的页表， 形成要访问数据的物理地址，读取内存数据

- 页面置换算法的设计目标

	- 具有较低的页面更换频率——低缺页率

	- 找出以后不再访问的页面或者较长时间不再使用的页面

	- 算法种类

		- 最佳置换算法

			- 选择的页面：不再访问的或者较长时间不再使用

			- 优点：保证最低的缺页率

			- 缺点：不可能真正实现，只作为其他算法评价参考

			- 特点：“往后看”，看未来，理论上的算法，不可行

		- 先进先出算法

			- 淘汰最先进入内存的页面，即选择内存驻留时间最长的

			- 需要使用指针标识停留最久的位置

			- 优点：算法简单；缺点：性能不佳

			- 特点：只看“进入顺序”

		- 最近最久未使用（LRU）算法

			- 选择最近最久未使用的页面

			- 增加访问字段记录各个页面未被访问的周期数

			- 优点：性能较好；缺点：需要较多硬件支持

			- 特点： “向前看”，看过去的使用情况

			- LRU置换算法需要硬件支持

				- LRU硬件要解决的问题：进程各个页面有多久未被访问、如何快速找到最近最久未使用的页面

				- LRU硬件：移位寄存器、堆栈

		- Clock算法

			- LRU算法的近似算法，也称为最近未用算法

			- 为每页设置一访问位，当被访问则设置为1，未访问为0

			- 改进型Clock置换算法

				- 每个页面有访问位A和修改位M

				- 两个位组合成四种类型页面

				- 执行过程

					- 从当前指针位置开始扫描循环队列，寻找第1类页面，不改变访问位A，将遇到的第一个这类页面作为淘汰页

					- 第一步查找失败，寻找第2类页面，将遇到的第一个这类页面作为淘汰页。在扫描期间，所有扫描过的页面的访问位A都置0

					- 所有3类页面变成1类页面，4类页面变成2类页面

					- 第二步失败，重复第一步

					- 如果仍失败，再重复第二步，此时就一定能找到被淘汰的页

				- 优点：减少了磁盘的I/O操作次数

				- 缺点：可能需要几轮扫描，增加了系统开销

		- 其他算法

			- 最少使用置换算法(LFU： Least Frequently Used)

				- 对每个页面设置一个字段（移位寄存器），用来记录页面被访问的频率

			- 页面缓冲算法

				- 采用可变分配和局部置换方式

				- 当一个进程换进换出频率很低时，选择页面淘汰，以备其他进程使用

				- 被淘汰页面若发生修改，放入已修改链表，否则放入空闲链表

				- 修改链表的页面积累一定数量，一次性写回硬盘

- 请求分页性能分析

	- 工作集机制，有效降低缺页率，提高访存的时间效率

		- 工作集是指某段时间内，进程实际访问的页集合

	- 抖动

		- 概念：频繁的进行页换入换出，导致进程不能正常工作

		- 原因：OS中的进程数量太多，每个进程分配的页框太少

		- 预防方法

			- 采取局部置换策略

			- 在 CPU 调度程序中引入工作集算法

			- 挂起若干进程

### 分段存储管理

- 概念

	- 分段是指将一个进程划分为多个具有逻辑意义而且相对独立的部分

	- 例如主程序段、数据段、堆栈段、子程序段等

	- X86常见的段基址：CS、SS、DS、ES

	- 每个段都是从0开始的独立逻辑地址空间

- 引入分段的好处

	- 方便编程

	- 分段共享

	- 分段保护

	- 动态链接

	- 存储空间的动态增长

- 分段的地址结构

	- 每个段都有独立的名称，为了管理方便，用段号表示

	- 在逻辑地址意义上，每个段地址包含两部分

	- 所以段地址是二维结构

- 段表，维护分段存储管理的地址映射机构

- 段地址变换过程

	- 若段号大于段表长度，越界错误

	- 查段表得到段基址和段长度

	- 若段内地址大于段长度，越界错误

	- 通过段基址和段内地址得到物理地址

	- 根据物理地址读取数据

- 分页与分段的区别

	- 页是信息的物理单位，满足系统空间管理需要。分页实现离散分配方式，以消减内存的外零头， 提高内存的利用率

	- 段是信息的逻辑单位，满足用户需要

	- 页的大小固定，由系统决定

	- 段的长度不固定， 由用户决定

	- 分页的作业地址空间是一维的

	- 分段的作业地址空间则是二维的

- 信息共享

	- 分段机制比分页机制更容易实现信息共享

	- 多个进程共享一个具有独立意义的段，实现很简单，只要在各自段表加入相同段基址和段长度就可以了

	- 例如Windows动态链接库中的纯代码段可以被多个进程共享

- 段页式管理的地址机构

	- 段面向用户程序需要，段长度不固定

	- 段需要连续分配空间，存在连续分配的缺点，例如易产生碎片

	- 结合段式和页式两者管理优点，既能节省内存空间，提高内存分配效率；又能兼顾用户程序需要

- 段页式管理的机制

	- 分段与分页机制的结合

	- 先将用户程序划分为多个有逻辑意义的段，再将段划分为多个页

	- 段页式管理需要设置段表和页表

	- 每个段都对应一张页表，因此段表存放了每张页表的开始地址和页表长度

	- 基本原理：先分段，后分页

	- 地址映射：先查段表，再查页表

### Linux的伙伴系统

- 将所有空闲页框分为11个块链表

- 每个块链表的块大小固定为：1、2、4、8、.....1024，单位是KB

- 块的分配和回收，操作不同级别的链表

## 文件系统

### 指由创建者所定义的、 具有文件名的一组相关元素的集合

### 文件

- 名称

- 类型

	- 正规文件

		- ASCII

		- 二进制

	- 目录文件

	- 字符设备文件

	- 块设备文件

- 属性

- 操作

### 文件结构

- 无结构字节序列，流式文件

- 固定长度记录序列

- 树形结构

### 目录

- 目录结构

	- 单层

	- 两级

	- 树形

### 文件分配

- 分配方式

	- 连续分配

		- 为文件分配一组相邻接的盘块

		- 优点

			- 顺序访问实现容易，访问速度快

		- 缺点

			- 要求有连续的存储空间，易产生碎片(空洞)

	- 使用磁盘链接表的分配

		- 为文件构造簇链接表，指针放在磁盘块中

		- 优点

			- 不存在碎片、不需要连续空间

		- 缺点

			- 适合顺序访问，不适合随机访问；可靠性差，其中某个指针出错将 导致后面数据丢失；因为指针占用数据区，数据区大小不等于2的n次幂， 不利于和内存页对应

	- 使用内存的链接表分配

		- 簇号放在内存表

		- 缺点

			- 不支持高速直接存取

	- i-节点

		- 为每个文件分配索引表，将文件所有盘块记录在索引表中

		- i 节点的多级索引分配

			- 优点：支持更大的文件长度

			- 缺点：需要更多的额外空间

## 输入输出设备

### IO 系统的组成

- 主要功能

	- 缓冲区管理

	- 设备控制

	- 设备分配

	- 实现设备独立性

	- 虚拟设备

- 任务

	- 完成 IO 请求，提高 IO 速率，提高 IO 设备利用率

- 结构

	- 微机

		- 总线型

	- 主机

		- 四级结构

- 设备种类

	- 按速率划分

		- 低速设备（<= 1KB）

			- 键鼠设备

		- 中速设备（1KB - 100KB/s）

			- 打印机

		- 高速设备（> 100KB）

			- 磁盘机，光盘机

	- 按信息交换单位划分

		- 块设备

			- 用户存储信息，以数据块为单位

				- 磁盘

		- 字符设备

			- 用户传输信息，传送字节流

				- 鼠标、终端

	- 按共享属性分类

		- 独占设备

			- 必须作为临界资源以互斥方式访问的设备

		- 共享设备

			- 允许多个用户共同使用，并发使用，典型设备是硬盘

		- 虚拟设备

			- 采用软硬件技术将一台物理设备变为多个逻辑设备

- 设备控制器

	- 概念

		- 一个计算机实体：可以嵌在主板、独立板卡或嵌入设备

		- CPU与I/O设备的接口

		- 控制多个I/O设备

		- 实现I/O设备与主机的数据交换

		- 可编址设备，通过I/O地址识别不同的设备

	- 功能

		- 接收和识别命令

		- 数据交换

		- 标识和报告设备的状态

		- 地址识别

		- 数据缓冲

		- 差错控制

	- 组成

		- 设备控制器与处理机的接口：数据线、控制线、地址线

		- 设备控制器与设备的接口，含数据信号、状态信号、控制信号

		- I/O逻辑，包含指令译码器、地址译码器

	- IO 通道是一种特殊的处理机，是一个硬件设备

		- 具有执行I/O指令的能力

		- 通过执行通道(I/O)程序控制I/O操作

		- 指令类型单一，主要限于与I/O操作有关的指令

		- 没有自己的内存，通道程序放在主机内存中

	- I/O通道使CPU从控制I/O任务中解脱

		- CPU与I/O并行

		- 提高CPU利用率

		- 提高系统吞吐量

### IO 控制方式

- 目标

	- 尽量减少主机对I/O控制的干预

	- 提高主机和I/O的并行

	- 提高系统整体性能

- 方式

	- 轮询

	- 中断

	- DMA

- 步骤

	- 设备启动

	- 传输参数初始化

	- 传输过程的控制（地址变化，传输计数）

	- 传输结束

- 改进思路

	- 尽量释放CPU，减少CPU负担

### 缓冲管理

- 引入缓冲区的主要原因

	- 处理数据流的生产者和消费者之间的速度差异

	- 协调传输数据大小不一致的设备，常见于网络传输

- 解决的问题

	- 缓和CPU与I/O设备间速度不匹配的矛盾

	- 降低CPU中断频率要求， 放宽对CPU中断响应时间的限制

	- 提高CPU和I/O设备之间的并行性

- 单缓冲

- 双缓冲

	- 运行周期：Max(C+M, T)，增加了复杂性

	- C+M<T：主机速度快，主机等待，磁盘连续输入

	- C+M>T：磁盘速度快，磁盘等待，主机连续运行

- 循环缓冲

	- 三类缓冲区：空白R、装满G、执行C

- 缓冲池

	- 三种缓冲区：空闲、输入数据、输出数据

	- 三个队列：空缓冲队列、输入队列、输出队列

	- 两个进程：PutBuf和GetBuf

	- 四种工作方式：收容输入、提取输入、收容输出、提取输出

### 设备分配

- 设备分配程序基于一定策略，把设备分配给用户

- 设备分配需要

	- 记录设备情况的数据结构

	- 设备分配算法

- 考虑因素

	- 设备固有属性：独占、共享、可虚拟

	- 设备分配算法：FIFO、基于优先权

	- 设备分配时的安全性：安全分配、不安全分配

- 设备独立性

	- 好处

		- 无关性

		- 易于处理故障

		- 提高系统可靠性、灵活性

- 设备独立软件的功能

	- 执行所有设备的公有操作

	- 向用户层软件提供统一的接口

- 独占设备的分配程序

	- 分配设备

	- 分配控制器

	- 分配通道

- SPOOLing 技术

	- 利用一道程序模拟脱机输入时外围控制机功能，I/O设备数据传入磁盘

	- 利用一道程序模拟脱机输出时外围控制机功能，磁盘数据传出I/O设备

	- 组成

		- 输入井和输出井

		- 输入缓冲区、输出缓冲区

		- 输入进程、输出进程

		- 请求 IO 队列

	- 特点

		- 提高了 IO 速度

		- 将独占设备改造为共享设备

		- 实现了虚拟设备功能

### IO 软件管理

- 目标

	- 把软件组织成层次结构

	- 低层软件屏蔽硬件具体细节

	- 高层软件向用户提供简洁规范界面

- 设备管理软件组织4个层次

	- 用户层软件

	- 设备无关软件层

	- 设备驱动程序

	- 中断处理程序

- 设备管理软件的功能

	- 实现 IO 设备的独立性

	- 错误处理

	- 异步传输

	- 缓冲管理

	- 设备的分配和释放

	- 实现 IO 控制方式

- 中断处理程序

	- 完成进程阻塞和释放 CPU

- 设备驱动程序的功能

	- 计算出所请求块的物理地址

	- 检查驱动器电机是否正在运转

	- 检查磁头臂是否定位在正确的柱面

	- 确定需要哪些控制器命令及命令的执行顺序

	- 向设备控制器的设备寄存器中写入命令

	- IO 完成后，向上层软件传送数据

- 与硬件无关的 IO 软件功能

	- 设备命名

	- 设备保护

	- 提供独立于设备的块大小

	- 为块设备和字符设备提供必要的缓冲技术

	- 块设备的存储分配

	- 分配和释放独立设备

	- 错误处理

### 磁盘管理

- 目标

	- 提高磁盘空间利用率和磁盘访问速度

- 结构

	- 盘片

	- 磁道

	- 扇区

- 类型

	- 固定头磁盘，每条磁道都有磁头，用于大容量磁盘

	- 移动头磁盘：一个盘面配有一个磁头，用于中小型磁盘

- 访问时间

	- 旋转时间

		- 扇区移动到磁头下面的时间

	- 寻道时间

		- 磁头移动到指定磁道上的时间

	- 传输时间

		- 数据从磁盘读出或写入磁盘

- 提高磁盘 IO 速度的方法

	- 提升磁盘硬件性能

	- 采用好的调度算法

	- 设置磁盘高速缓冲区

- 磁盘调度

	- 磁盘属于共享设备，允许多个进程访问，因此需要磁盘调度算法

	- 磁盘调度算法目标是平均寻道时间少

- 磁盘调度算法

	- 先来先服务

		- 优点：简单，每个请求按照时间顺序来处理

		- 缺点：平均寻道距离较大

	- 最短寻道时间优先

		- 优点：平均寻道时间较短

		- 缺点

			- 饥饿现象，即某些进程长期得不到访问

			- “磁臂粘着”现象，即磁头可能长期停留 在同一磁道

	- 扫描

		- 依据磁头移动方向访问当前磁道最近的目标磁道

		- 解决了“饥饿”现象，平均寻道时间较短

		- “磁臂粘着”现象仍未解决

		- 又称为电梯调度算法

	- 循环扫描

		- 磁头移动方向固定不变，不会中途折返。
到达最外磁道后，返回最内磁道开始扫描算法

		- 优点：不会出现“饥饿”现象，平均寻道时间 较短，最长等待时间比扫描算法少一半

		- 缺点：”磁臂粘着”现象仍未解决

## 2018 年开始考题

2,3,4 (6) 章重点

信号量编程，必考，10分
三种CPU调度算法，必考，10分
银行家算法，可能考，10分
基本分页的5个考点组合，必考，10分
四种磁盘调度算法，必考，10分

